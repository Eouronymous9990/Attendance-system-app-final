{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 found in data\n",
      "Encoding images loaded\n",
      "Encoding images loaded\n",
      "Encoding images loaded\n",
      "Encoding images loaded\n",
      "Encoding images loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\zbook 17 g3\\AppData\\Local\\Temp\\ipykernel_2692\\2589533047.py\", line 58, in start_webcam\n",
      "    update_canvas()  # Start updating the canvas\n",
      "  File \"C:\\Users\\zbook 17 g3\\AppData\\Local\\Temp\\ipykernel_2692\\2589533047.py\", line 144, in update_canvas\n",
      "    face_locations,face_names=my_class.detect_frames(frame)\n",
      "  File \"C:\\Users\\zbook 17 g3\\AppData\\Local\\Temp\\ipykernel_2692\\2589533047.py\", line 99, in detect_frames\n",
      "    frame= cv2.resize(frame, (0, 0), fx=.25, fy=.25)\n",
      "cv2.error: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tkinter as tk\n",
    "from tkinter.ttk import *\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import cvzone\n",
    "import threading\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import face_recognition\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "from streamlit_webrtc import webrtc_streamer, VideoTransformerBase\n",
    "\n",
    "\n",
    "# Global variables for OpenCV-related objects and flags\n",
    "cap = None\n",
    "is_camera_on = False\n",
    "\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "def add_one(name) :\n",
    "\n",
    "    excel_file_path = r\"E:\\project\\sheet 111.xlsx\"\n",
    "    target_value = name\n",
    "\n",
    "    df = pd.read_excel(excel_file_path, engine='openpyxl')\n",
    "\n",
    "    if target_value in df['data'].values:\n",
    "        df.loc[df['data'] == target_value, 'value'] = 1\n",
    "\n",
    "    df.to_excel(excel_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "\n",
    "# Function to start the webcam feed\n",
    "def start_webcam():\n",
    "    global cap, is_camera_on\n",
    "    if not is_camera_on:\n",
    "        cap = cv2.VideoCapture(0)  # Use the default webcam (you can change the index if needed)\n",
    "        is_camera_on = True\n",
    "        update_canvas()  # Start updating the canvas\n",
    "\n",
    "# Function to stop the webcam feed\n",
    "def stop_webcam():\n",
    "    global cap, is_camera_on\n",
    "    if cap is not None:\n",
    "        cap.release()\n",
    "        is_camera_on = False\n",
    "        \n",
    "        \n",
    "class facerecognition : \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.saved_names=[]\n",
    "        self.saved_encodings=[]\n",
    "        \n",
    "        \n",
    "    def uppload_data (self,data_path):\n",
    "        data_path=glob.glob(os.path.join(data_path, \"*.*\"))\n",
    "        print(\"{} found in data\".format(len(data_path)))\n",
    "        \n",
    "        \n",
    "        for img_path in data_path :\n",
    "            img=cv2.imread(img_path)\n",
    "            img_rgb=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            encoo = face_recognition.face_encodings(img_rgb)[0]\n",
    "            basename=os.path.basename(img_path)\n",
    "            (name,extention)=os.path.splitext(basename)\n",
    "            self.saved_names.append(name)\n",
    "            self.saved_encodings.append(encoo)\n",
    "            \n",
    "            print(\"Encoding images loaded\")\n",
    "    \n",
    "        return self.saved_names\n",
    "            \n",
    "\n",
    "              \n",
    "    def detect_frames(self,frame)  :\n",
    "        \n",
    "        #preprocessing\n",
    "        frame= cv2.resize(frame, (0, 0), fx=.25, fy=.25)\n",
    "        frame_rgb=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        location=face_recognition.face_locations(frame_rgb)\n",
    "        frame_encodings = face_recognition.face_encodings(frame_rgb,location)\n",
    "        \n",
    "        \n",
    "        #as we working on real time data we will use for loop\n",
    "        face_names=[]\n",
    "        for enc in frame_encodings :\n",
    "            \n",
    "            compare = face_recognition.compare_faces(self.saved_encodings, enc)\n",
    "            name = \"Not_recognized_face\"\n",
    "            \n",
    "            face_distances = [face_recognition.face_distance([saved_enc], enc) for saved_enc in self.saved_encodings]\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if compare[best_match_index]:\n",
    "                name = self.saved_names[best_match_index]\n",
    "                print(name)\n",
    "            face_names.append(name)\n",
    "            #print(self.saved_names)\n",
    "        \n",
    "        \n",
    "        \n",
    "        face_locations = np.array(location)\n",
    "        face_locations = face_locations / .25\n",
    "        \n",
    "        return face_locations.astype(int), face_names\n",
    "\n",
    "\n",
    "my_class=facerecognition()\n",
    "# Function to update the Canvas with the webcam frame or video frame\n",
    "def update_canvas():\n",
    "    global is_camera_on\n",
    "    if is_camera_on:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "            \n",
    "\n",
    "        my_class=facerecognition()\n",
    "\n",
    "        my_class.uppload_data(r\"C:\\Users\\zbook 17 g3\\Desktop\\CV PROJECTS\\New folder (4)\")\n",
    "\n",
    "\n",
    "         \n",
    "\n",
    "        face_locations,face_names=my_class.detect_frames(frame)\n",
    "\n",
    "        for face_loc, name in zip(face_locations, face_names):\n",
    "        \n",
    "            y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "\n",
    "        \n",
    "            if name==\"Not_recognized_face\" :\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 200), 4)\n",
    "                cv2.putText(frame, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)\n",
    "            else :\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 200, 0), 4)    \n",
    "                cv2.putText(frame, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0), 2)\n",
    "            \n",
    "        \n",
    "        #markAttendance(name)\n",
    "            add_one(name)\n",
    "      \n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (520, 380))\n",
    "\n",
    "        photo = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "        canvas.img = photo\n",
    "        canvas.create_image(0, 0, anchor=tk.NW, image=photo)\n",
    "\n",
    "    canvas.after(1, update_canvas)\n",
    "\n",
    "\n",
    "# Function to quit the application\n",
    "def quit_app():\n",
    "    stop_webcam()\n",
    "    root.quit()\n",
    "    root.destroy()\n",
    "\n",
    "# Create the main Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Attendance system\")\n",
    "\n",
    "# Create a Canvas widget to display the webcam feed or video\n",
    "canvas = tk.Canvas(root, width=1020, height=500)\n",
    "canvas.pack(fill='both', expand=True)\n",
    "\n",
    "\n",
    "button_frame = tk.Frame(root)\n",
    "button_frame.pack(fill='x')\n",
    "\n",
    "play_button = tk.Button(button_frame, text=\"Play\", command=start_webcam)\n",
    "play_button.pack(side='left')\n",
    "\n",
    "stop_button = tk.Button(button_frame, text=\"Stop\", command=stop_webcam)\n",
    "stop_button.pack(side='left')\n",
    "\n",
    "\n",
    "quit_button = tk.Button(button_frame, text=\"Quit\", command=quit_app)\n",
    "quit_button.pack(side='left')\n",
    "\n",
    "initial_image = Image.open(r\"C:\\Users\\zbook 17 g3\\Desktop\\New folder (2)\\dataset\\foggy\\foggy232.jpg\")  # Replace 'initial_image.jpg' with your image path\n",
    "initial_photo = ImageTk.PhotoImage(image=initial_image)\n",
    "canvas.img = initial_photo\n",
    "canvas.create_image(0, 0, anchor=tk.NW, image=initial_photo)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\zbook 17 g3\\\\Desktop'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
